{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0dab46-aa21-428d-918f-0f61f68307f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d8b513-4e77-4705-bb0b-875a98a450c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial weight scale\n",
    "init_scale = 0.1\n",
    "#Initial learning rate\n",
    "learning_rate = 1.0\n",
    "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
    "max_grad_norm = 5\n",
    "#The number of layers in our model\n",
    "num_layers = 2\n",
    "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
    "num_steps = 20\n",
    "#The number of processing units (neurons) in the hidden layers\n",
    "hidden_size_l1 = 256\n",
    "hidden_size_l2 = 128\n",
    "#The maximum number of epochs trained with the initial learning rate\n",
    "max_epoch_decay_lr = 4\n",
    "#The total number of epochs in training\n",
    "max_epoch = 15\n",
    "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
    "#At 1, we ignore the Dropout Layer wrapping.\n",
    "keep_prob = 1\n",
    "#The decay for the learning rate\n",
    "decay = 0.5\n",
    "#The size for each batch of data\n",
    "batch_size = 30\n",
    "#The size of our vocabulary\n",
    "vocab_size = 10000\n",
    "embeding_vector_size= 200\n",
    "#Training flag to separate training from testing\n",
    "is_training = 1\n",
    "#Data directory for our dataset\n",
    "data_dir = \"data/simple-examples/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70bd12b-db94-4904-9e82-358eccae8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def _read_words(filename):\n",
    "  with tf.io.gfile.GFile(filename, \"r\") as f:\n",
    "    return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "\n",
    "def _build_vocab(filename):\n",
    "  data = _read_words(filename)\n",
    "\n",
    "  counter = collections.Counter(data)\n",
    "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "  words, _ = list(zip(*count_pairs))\n",
    "  word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "  return word_to_id\n",
    "\n",
    "\n",
    "def _file_to_word_ids(filename, word_to_id):\n",
    "  data = _read_words(filename)\n",
    "  return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "\n",
    "def ptb_raw_data(data_path=None):\n",
    "  \"\"\"Load PTB raw data from data directory \"data_path\".\n",
    "\n",
    "  Reads PTB text files, converts strings to integer ids,\n",
    "  and performs mini-batching of the inputs.\n",
    "\n",
    "  The PTB dataset comes from Tomas Mikolov's webpage:\n",
    "\n",
    "  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "\n",
    "  Args:\n",
    "    data_path: string path to the directory where simple-examples.tgz has\n",
    "      been extracted.\n",
    "\n",
    "  Returns:\n",
    "    tuple (train_data, valid_data, test_data, vocabulary)\n",
    "    where each of the data objects can be passed to PTBIterator.\n",
    "  \"\"\"\n",
    "\n",
    "  train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "  valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "  test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "  word_to_id = _build_vocab(train_path)\n",
    "  train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "  valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "  test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "  vocabulary = len(word_to_id)\n",
    "  return train_data, valid_data, test_data, vocabulary, word_to_id\n",
    "\n",
    "\n",
    "def ptb_iterator(raw_data, batch_size, num_steps):\n",
    "  \"\"\"Iterate on the raw PTB data.\n",
    "\n",
    "  This generates batch_size pointers into the raw PTB data, and allows\n",
    "  minibatch iteration along these pointers.\n",
    "\n",
    "  Args:\n",
    "    raw_data: one of the raw data outputs from ptb_raw_data.\n",
    "    batch_size: int, the batch size.\n",
    "    num_steps: int, the number of unrolls.\n",
    "\n",
    "  Yields:\n",
    "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n",
    "    The second element of the tuple is the same data time-shifted to the\n",
    "    right by one.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if batch_size or num_steps are too high.\n",
    "  \"\"\"\n",
    "  raw_data = np.array(raw_data, dtype=np.int32)\n",
    "\n",
    "  data_len = len(raw_data)\n",
    "  batch_len = data_len // batch_size\n",
    "  data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
    "  for i in range(batch_size):\n",
    "    data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
    "\n",
    "  epoch_size = (batch_len - 1) // num_steps\n",
    "\n",
    "  if epoch_size == 0:\n",
    "    raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
    "\n",
    "  for i in range(epoch_size):\n",
    "    x = data[:, i*num_steps:(i+1)*num_steps]\n",
    "    y = data[:, i*num_steps+1:(i+1)*num_steps+1]\n",
    "    yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b28f51-d353-4056-b775-80e1a47dfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcb929a-330c-4585-a59d-49e8a85ee2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = ptb_iterator(train_data, batch_size, num_steps)\n",
    "first_touple = itera.__next__()\n",
    "_input_data = first_touple[0]\n",
    "_targets = first_touple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3631c8bf-e064-4ee0-9ec5-d2f8dc3c953e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e1c324-cc59-4063-96ad-4df8115fc017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
     ]
    }
   ],
   "source": [
    "def id_to_word(id_list):\n",
    "    line = []\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "    return line            \n",
    "                \n",
    "\n",
    "print(id_to_word(train_data[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37522117-ecc5-466f-a038-206dbd37684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a854553-f57c-4a1b-812e-5fb27008d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbe44143-d7fc-414a-9bde-f82895a11497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
       "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
       "          12,    3,   21,    2, 2915,    2,   12,    3,   21]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa18f6a8-fc3f-4f66-8523-50640743c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(_input_data[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d1f7c08-edd8-4929-8e4a-09ca7bfa7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(vocab_size, embeding_vector_size,batch_input_shape=(batch_size, num_steps),trainable=True,name=\"embedding_vocab\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02858bea-6e95-4fa6-ba4c-64a943720e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 20, 200), dtype=float32, numpy=\n",
       "array([[[ 1.50108449e-02, -4.42440286e-02,  1.12416968e-02, ...,\n",
       "          2.43944861e-02, -4.04040702e-02,  4.42680977e-02],\n",
       "        [ 1.20785609e-02,  2.64554955e-02,  2.90320627e-02, ...,\n",
       "          1.53687038e-02,  2.37068050e-02, -1.35993473e-02],\n",
       "        [-2.84717437e-02,  4.75924648e-02, -6.42641634e-03, ...,\n",
       "         -4.99358289e-02,  3.76529135e-02, -5.31923771e-03],\n",
       "        ...,\n",
       "        [ 8.13189894e-03,  4.56289202e-03,  1.50487572e-03, ...,\n",
       "          4.55789007e-02, -3.95794883e-02, -3.57348323e-02],\n",
       "        [ 3.66412476e-03, -4.65956591e-02, -1.68618187e-02, ...,\n",
       "          4.06797864e-02,  8.03351402e-04,  1.96575634e-02],\n",
       "        [-4.32941914e-02, -4.82794642e-02,  2.91109085e-03, ...,\n",
       "          7.79502466e-03,  3.52755524e-02, -3.83252129e-02]],\n",
       "\n",
       "       [[ 3.01200785e-02, -2.64297798e-03, -1.04435198e-02, ...,\n",
       "          6.47775084e-03, -2.31964476e-02, -3.74848954e-02],\n",
       "        [-1.81778893e-02, -4.22095433e-02, -2.10608598e-02, ...,\n",
       "         -1.11881606e-02,  2.57500522e-02, -9.58795473e-03],\n",
       "        [-1.29554868e-02,  1.79448985e-02,  4.91399877e-02, ...,\n",
       "         -1.32175796e-02, -9.91940498e-03,  7.74673373e-03],\n",
       "        ...,\n",
       "        [-1.62636265e-02,  8.51931423e-03, -4.88597155e-03, ...,\n",
       "          6.58988953e-03, -4.63370197e-02,  4.94912975e-02],\n",
       "        [-7.79330730e-04, -4.35158387e-02,  4.36277427e-02, ...,\n",
       "         -2.42337827e-02, -4.31216024e-02,  1.33980066e-04],\n",
       "        [ 2.82634832e-02, -3.25392112e-02,  8.87881964e-04, ...,\n",
       "         -2.19224580e-02, -2.11350676e-02, -1.42529979e-02]],\n",
       "\n",
       "       [[ 2.61747725e-02,  1.39909126e-02, -1.24511495e-02, ...,\n",
       "         -1.71738043e-02,  4.41635586e-02, -4.21694405e-02],\n",
       "        [-2.80776378e-02, -1.74651630e-02,  3.89506333e-02, ...,\n",
       "         -8.29295069e-03, -3.42628956e-02, -4.15569171e-02],\n",
       "        [-3.24124470e-02, -1.48479939e-02,  1.95678361e-02, ...,\n",
       "         -2.13986170e-02, -4.26093228e-02, -2.58369446e-02],\n",
       "        ...,\n",
       "        [ 2.93446667e-02,  4.88790981e-02, -2.90688518e-02, ...,\n",
       "          2.40255259e-02,  2.10980214e-02, -2.02665683e-02],\n",
       "        [-8.38017464e-03,  2.91225575e-02, -2.06653122e-02, ...,\n",
       "          1.74604319e-02,  3.58857028e-02,  3.13255675e-02],\n",
       "        [ 3.50801386e-02, -1.68661848e-02,  3.22632901e-02, ...,\n",
       "         -1.93630941e-02,  4.04445194e-02, -3.94771323e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.39343490e-02, -3.65490541e-02, -2.88061388e-02, ...,\n",
       "         -2.08268650e-02, -4.74641435e-02, -5.76595217e-03],\n",
       "        [ 1.63682960e-02, -4.83750589e-02, -2.01278925e-03, ...,\n",
       "          3.38563211e-02,  3.94085981e-02, -2.78052930e-02],\n",
       "        [-3.39443609e-03, -5.96040487e-03,  4.23166901e-03, ...,\n",
       "         -1.67746767e-02, -2.81882044e-02, -4.40949090e-02],\n",
       "        ...,\n",
       "        [ 1.88418962e-02,  1.38827413e-03,  3.32281701e-02, ...,\n",
       "         -5.89002296e-03, -2.82713305e-02,  4.79346178e-02],\n",
       "        [-4.84014861e-02,  4.16558050e-02,  2.00637020e-02, ...,\n",
       "         -1.77680142e-02,  6.02384657e-03, -9.50698927e-03],\n",
       "        [ 4.08002622e-02,  1.15048066e-02, -7.99857080e-04, ...,\n",
       "         -6.83784485e-03, -3.12561616e-02,  3.62386964e-02]],\n",
       "\n",
       "       [[ 1.20596401e-02,  3.91374342e-02, -4.44298051e-02, ...,\n",
       "          8.50441307e-03, -4.91760485e-02, -4.38932292e-02],\n",
       "        [ 3.58092301e-02, -3.22032459e-02, -3.04717310e-02, ...,\n",
       "         -4.42339294e-02,  1.99195854e-02, -4.49062251e-02],\n",
       "        [-3.24124470e-02, -1.48479939e-02,  1.95678361e-02, ...,\n",
       "         -2.13986170e-02, -4.26093228e-02, -2.58369446e-02],\n",
       "        ...,\n",
       "        [ 4.17164452e-02,  2.77997367e-02,  4.70528044e-02, ...,\n",
       "         -4.78457287e-03, -4.19544354e-02,  7.69297034e-03],\n",
       "        [-1.81778893e-02, -4.22095433e-02, -2.10608598e-02, ...,\n",
       "         -1.11881606e-02,  2.57500522e-02, -9.58795473e-03],\n",
       "        [-8.30986351e-03, -2.02474482e-02, -1.49395242e-02, ...,\n",
       "         -3.21163163e-02,  4.88977097e-02,  1.16412528e-02]],\n",
       "\n",
       "       [[ 2.74242647e-02,  3.56985666e-02, -8.75480473e-05, ...,\n",
       "          1.00869536e-02, -1.51350498e-02,  1.99100487e-02],\n",
       "        [ 6.73651695e-03, -4.93796244e-02,  3.72089781e-02, ...,\n",
       "          3.20318602e-02,  1.08374730e-02, -1.89395081e-02],\n",
       "        [ 1.84548236e-02,  4.31273133e-03, -2.59072706e-03, ...,\n",
       "          3.61417420e-02,  4.27139141e-02, -1.51616447e-02],\n",
       "        ...,\n",
       "        [-4.52509783e-02, -4.70408797e-02,  2.28472985e-02, ...,\n",
       "         -1.78284645e-02, -3.33566070e-02, -2.27988251e-02],\n",
       "        [ 4.50651161e-02,  2.99364813e-02, -2.76372787e-02, ...,\n",
       "          4.65837382e-02, -3.28600407e-03, -4.90823165e-02],\n",
       "        [ 4.95615043e-02,  1.01508498e-02, -4.06964906e-02, ...,\n",
       "          4.20942158e-03, -4.13456932e-02,  4.52225693e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define where to get the data for our embeddings from\n",
    "inputs = embedding_layer(_input_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fb96a6c-0b1c-42ab-a61f-a2f11fe55d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
    "lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "309935af-8d66-4b92-a08c-c50d0408feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "155abfee-364a-4fc4-8678-7fbce7cc1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8d6d871-cf76-426f-b097-5c800a49c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e117cd5-46d7-4eeb-ad74-0a60c68d2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.inital_state = init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4aab38-ab1c-4b07-8ed0-b5d7ccfd70ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30, 200) dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.inital_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5afe3396-0419-4bc3-9280-d1469841fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc853cee-18b7-4f57-94dd-d2864c5029f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 20, 128), dtype=float32, numpy=\n",
       "array([[[-2.6952322e-03,  4.5033570e-04,  5.4306656e-05, ...,\n",
       "          8.5960777e-04,  1.8866402e-03,  6.0933287e-04],\n",
       "        [-3.3794567e-03,  6.1050378e-04,  1.4076863e-03, ...,\n",
       "          4.0729993e-04,  3.7723926e-03,  5.4415310e-04],\n",
       "        [-3.7586431e-03,  1.0147203e-03,  3.2546448e-03, ...,\n",
       "          6.2232510e-05,  5.4535954e-03,  1.6946403e-03],\n",
       "        ...,\n",
       "        [-2.5281128e-03,  5.7684905e-03,  1.3206020e-04, ...,\n",
       "          5.6485208e-03, -2.8833998e-03,  3.8751289e-03],\n",
       "        [-2.8725807e-03,  5.1796916e-03,  5.8878789e-04, ...,\n",
       "          5.6287958e-03, -1.7468049e-03,  2.6915951e-03],\n",
       "        [-2.6211594e-03,  4.2598727e-03,  1.5286102e-03, ...,\n",
       "          5.3600552e-03, -1.8374330e-03,  9.6161669e-04]],\n",
       "\n",
       "       [[-1.1035381e-03,  5.4230622e-04, -6.3420908e-04, ...,\n",
       "         -3.7029269e-05,  9.0331573e-04,  1.6269424e-03],\n",
       "        [-1.8234245e-03,  1.4717091e-04, -1.6896909e-03, ...,\n",
       "         -1.2616612e-03,  1.9589027e-03,  2.0207216e-03],\n",
       "        [-1.6630702e-03,  4.8153306e-04, -3.1333803e-03, ...,\n",
       "         -2.1927629e-03,  7.7797659e-04,  1.4710593e-03],\n",
       "        ...,\n",
       "        [ 5.4883456e-04, -1.6544445e-03,  8.8506229e-03, ...,\n",
       "          3.2641347e-03,  2.2176944e-03, -3.9774021e-03],\n",
       "        [ 1.1384672e-03, -1.1008644e-03,  8.7886527e-03, ...,\n",
       "          3.2619259e-03,  1.9686739e-03, -4.7355494e-03],\n",
       "        [ 3.9239053e-04,  2.0070808e-04,  8.5372645e-03, ...,\n",
       "          4.1700276e-03,  2.4457842e-03, -5.0423294e-03]],\n",
       "\n",
       "       [[-4.0398887e-04, -2.7399044e-04,  1.6617009e-03, ...,\n",
       "         -5.6113460e-04,  2.1924498e-04,  1.6448724e-03],\n",
       "        [-1.7225815e-04, -6.0756441e-04,  3.6033147e-03, ...,\n",
       "         -1.4367115e-03, -5.6590897e-04,  9.5347181e-04],\n",
       "        [-9.9640759e-04, -7.3773228e-04,  4.6757939e-03, ...,\n",
       "         -2.1939273e-03, -9.0279436e-04, -1.9420590e-04],\n",
       "        ...,\n",
       "        [ 1.0263457e-02, -1.6965562e-03,  3.9920635e-03, ...,\n",
       "         -2.3591772e-03,  1.2754522e-03, -3.4361777e-03],\n",
       "        [ 1.1883733e-02, -1.6276514e-04,  3.6255934e-03, ...,\n",
       "         -2.2676585e-03,  1.1146944e-03, -4.7903587e-03],\n",
       "        [ 1.1298618e-02,  1.8823179e-04,  3.0525443e-03, ...,\n",
       "         -5.6484074e-04,  7.6427188e-04, -4.9380586e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.4003358e-04,  6.6097692e-04, -1.3864773e-03, ...,\n",
       "          2.2350578e-03, -9.8018884e-04,  3.5125090e-04],\n",
       "        [ 4.6276554e-04,  1.9325769e-03, -5.3264864e-04, ...,\n",
       "          4.5201429e-03, -1.3024881e-03, -1.2716466e-03],\n",
       "        [ 8.1691495e-04,  3.0523587e-03, -2.9269501e-04, ...,\n",
       "          4.1312580e-03, -1.0794339e-03, -3.9561684e-03],\n",
       "        ...,\n",
       "        [ 6.3637611e-03, -7.2197855e-04,  9.8383881e-04, ...,\n",
       "         -2.2631011e-03,  2.1635124e-03, -2.7104400e-03],\n",
       "        [ 7.3464685e-03, -1.3044481e-03,  1.3961818e-03, ...,\n",
       "         -2.6439438e-03,  2.0764098e-03, -1.7969192e-03],\n",
       "        [ 7.0235962e-03, -7.2413683e-04,  1.1998005e-04, ...,\n",
       "         -3.0677102e-03,  2.4824126e-03, -1.5844351e-04]],\n",
       "\n",
       "       [[-6.2656024e-04,  1.7489138e-04, -1.2037320e-03, ...,\n",
       "         -6.9368450e-04,  7.8068557e-04, -7.7873422e-04],\n",
       "        [-2.7028093e-04,  5.5850286e-04, -2.6241029e-03, ...,\n",
       "         -7.7520509e-04,  3.1799427e-04, -1.4948513e-03],\n",
       "        [-8.3295477e-04,  8.0554385e-04, -3.0134246e-03, ...,\n",
       "         -1.2759962e-03,  2.4179116e-04, -2.2986277e-03],\n",
       "        ...,\n",
       "        [-1.7174644e-03, -1.3052508e-03,  5.2923779e-03, ...,\n",
       "         -6.4604944e-03, -2.3305987e-04,  4.6501821e-03],\n",
       "        [-2.1871240e-03, -1.7545695e-03,  4.6279156e-03, ...,\n",
       "         -6.6339043e-03,  1.0000205e-03,  4.3437625e-03],\n",
       "        [-1.3715076e-03, -1.6442236e-03,  4.4280333e-03, ...,\n",
       "         -7.0674988e-03,  8.0000196e-04,  3.4372623e-03]],\n",
       "\n",
       "       [[ 2.1936506e-04, -1.0037427e-03, -3.0262274e-04, ...,\n",
       "          8.2298374e-04,  1.3329458e-04, -2.4250695e-04],\n",
       "        [ 1.3102114e-03, -1.8028879e-03, -1.2698366e-03, ...,\n",
       "          1.0799484e-03,  6.9651258e-05, -2.1194784e-04],\n",
       "        [-6.1981345e-04, -1.9633209e-03, -1.8891166e-03, ...,\n",
       "          2.3508065e-03,  2.0584699e-03,  3.8699018e-05],\n",
       "        ...,\n",
       "        [ 3.9952337e-03, -4.6182497e-04,  2.1665355e-03, ...,\n",
       "          2.1686682e-03, -7.2724447e-06,  3.3910184e-03],\n",
       "        [ 4.4206684e-03,  8.3658926e-04,  2.6570978e-03, ...,\n",
       "          1.6298180e-03, -1.6163049e-03,  4.9989182e-03],\n",
       "        [ 4.4276086e-03,  2.2958464e-03,  2.2164781e-03, ...,\n",
       "          1.7581127e-03, -3.7904470e-03,  6.4102551e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc3a6dc4-18cc-45ca-8387-753d8baf5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4ffb7c5-676c-4c1c-a508-121c6100af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_outputs  = dense(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39348042-727b-4b8a-b8fc-aaf4c6d0577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output from dense layer:  (30, 20, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the output from dense layer: \", logits_outputs.shape) #(batch_size, sequence_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a4317ce-5598-4761-98fe-92f0cfbdcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.keras.layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37fdad65-25f2-4865-8c55-5d76f2c24713",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words_prob = activation(logits_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd88ad23-2be1-4a4a-8def-31d6d90aba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output from the activation layer:  (30, 20, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the output from the activation layer: \", output_words_prob.shape) #(batch_size, sequence_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce775190-7ee9-4a9f-8487-bee1fae24025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of observing words in t=0 to t=20 tf.Tensor(\n",
      "[[9.9988792e-05 9.9992787e-05 1.0002866e-04 ... 9.9998164e-05\n",
      "  1.0000114e-04 9.9992969e-05]\n",
      " [9.9977195e-05 9.9998215e-05 1.0003304e-04 ... 9.9993857e-05\n",
      "  9.9995937e-05 9.9980694e-05]\n",
      " [9.9976111e-05 1.0001556e-04 1.0001936e-04 ... 9.9996636e-05\n",
      "  9.9974968e-05 9.9979006e-05]\n",
      " ...\n",
      " [9.9957731e-05 1.0001304e-04 9.9945457e-05 ... 9.9929122e-05\n",
      "  9.9926889e-05 9.9999190e-05]\n",
      " [9.9915815e-05 1.0002562e-04 9.9893834e-05 ... 9.9931298e-05\n",
      "  9.9945879e-05 1.0001824e-04]\n",
      " [9.9895195e-05 1.0003477e-04 9.9885059e-05 ... 9.9943005e-05\n",
      "  9.9953148e-05 1.0003235e-04]], shape=(20, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability of observing words in t=0 to t=20\", output_words_prob[0,0:num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "815c2606-cce6-4c3d-a8ee-74f11690cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6174, 5125, 5125, 4918, 4918, 4918, 4918, 5494, 5494, 5494, 5817,\n",
       "       9207, 9207, 9058, 9058, 8264, 8264, 5740, 5611, 7852], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_words_prob[0,0:num_steps], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28587ee7-1e2a-42e8-8b51-c3c19c59da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e186df4-6dba-4b81-a43b-80852809c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(y_true, y_pred):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3c3d4fe-0816-4059-bd3f-66318a0bb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = crossentropy(_targets, output_words_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff634dbf-3eda-4bb3-9a9e-3e7a13210f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([9.2103615, 9.210463 , 9.210446 , 9.20994  , 9.210105 , 9.209935 ,\n",
       "       9.210304 , 9.210097 , 9.210672 , 9.209379 ], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc6ed382-68e0-4c8c-88ae-fe7a5b167056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=184.20657>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss / batch_size)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1827f89-61ea-417d-bf6f-c63b1b81d7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
